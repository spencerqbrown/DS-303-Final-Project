seq(1, 100, 1)
seq(10, 100, 10)
knitr::opts_chunk$set(echo = TRUE)
ms = seq(10, 100, 10)
ss = seq(1, 100, 1)
alphas = matrix(nrow=length(ss), ncol=length(ms))
for (i in seq(1:length(ms))) {
m = ms[i]
for (j in seq(1:length(ss))) {
s = ss[j]
c = s / m
alphas[j, i] = pt(c, m-1)
}
}
alphas
ms = seq(10, 100, 10)
ss = seq(1, 100, 1)
alphas = matrix(nrow=length(ms), ncol=length(ss))
for (i in seq(1:length(ms))) {
m = ms[i]
for (j in seq(1:length(ss))) {
s = ss[j]
c = s / m
alphas[i, j] = pt(c, m-1)
}
}
alphas
ms = seq(10, 100, 10)
ss = seq(5, 100, 5)
alphas = matrix(nrow=length(ms), ncol=length(ss))
for (i in seq(1:length(ms))) {
m = ms[i]
for (j in seq(1:length(ss))) {
s = ss[j]
c = s / m
alphas[i, j] = pt(c, m-1)
}
}
alphas
ms = seq(10, 100, 10)
ss = seq(10, 100, 10)
alphas = matrix(nrow=length(ms), ncol=length(ss))
for (i in seq(1:length(ms))) {
m = ms[i]
for (j in seq(1:length(ss))) {
s = ss[j]
c = s / m
alphas[i, j] = pt(c, m-1)
}
}
alphas
ms = seq(10, 100, 10)
ss = seq(10, 100, 10)
alphas = matrix(nrow=length(ms), ncol=length(ss))
for (i in seq(1:length(ms))) {
m = ms[i]
for (j in seq(1:length(ss))) {
s = ss[j]
c = s / m
alphas[i, j] = 1 - pt(c, m-1)
}
}
alphas
ms = seq(50, 200, 25)
ss = seq(10, 100, 10)
alphas = matrix(nrow=length(ms), ncol=length(ss))
for (i in seq(1:length(ms))) {
m = ms[i]
for (j in seq(1:length(ss))) {
s = ss[j]
c = s / m
alphas[i, j] = 1 - pt(c, m-1)
}
}
alphas
knitr::opts_chunk$set(echo = TRUE)
library(MASS)
# we get a stepwise selected model using MASS.
model.step = stepAIC(model.fit, trace=FALSE)
knitr::opts_chunk$set(echo = TRUE)
df = read.csv("data.csv")
str(df)
df$Return.to.Prison = as.character(df$Return.to.Prison)
df$Return.to.Prison[df$Return.to.Prison == "Yes"] = "TRUE"
df$Return.to.Prison[df$Return.to.Prison == "No"] = "FALSE"
df$Return.to.Prison = as.logical(df$Return.to.Prison)
df$Target.Population = as.character(df$Target.Population)
df$Target.Population[df$Target.Population == "Yes"] = "TRUE"
df$Target.Population[df$Target.Population == "No"] = "FALSE"
df$Target.Population = as.logical(df$Target.Population)
str(df)
# find all columns with NA using an apply of anyNA on each column
colnames(df)[apply(df, 2, anyNA)]
cat("Total NA rows:", sum(is.na(df$Days.to.Return)),"\n")
cat("Rows total:", nrow(df), "\n")
cat("Proportion of rows NA:", sum(is.na(df$Days.to.Return)) / nrow(df))
# we can see if there any NAs that aren't matched with those that did not return to prison
length(df$Days.to.Return[(is.na(df$Days.to.Return)) & (df$Return.to.Prison == TRUE)])
levels(df$Offense.Classification)
levels(df$Offense.Type)
levels(df$Offense.Subtype)
levels(df$New.Offense.Type)
levels(df$New.Offense.Sub.Type)
sum(as.character(df$Offense.Type) == as.character(df$New.Offense.Type))
length(df$New.Offense.Type[(df$New.Offense.Type == "") | (df$New.Offense.Sub.Type == "")])
library(ggplot2)
df$Offense.Type = reorder(df$Offense.Type, df$Offense.Type, length)
df$Offense.Subtype = reorder(df$Offense.Subtype, df$Offense.Subtype, length)
df$New.Offense.Type = reorder(df$New.Offense.Type, df$New.Offense.Type, length)
df$New.Offense.Sub.Type = reorder(df$New.Offense.Sub.Type, df$New.Offense.Sub.Type, length)
df$Age.At.Release = reorder(df$Age.At.Release, df$Age.At.Release, length)
ggplot(df, aes(x=Offense.Type)) + geom_bar() + labs(x="Offense Type", y="Count", title="Count of Offenses by Type") + coord_flip()
ggplot(df, aes(x=Offense.Subtype)) + geom_bar() + labs(x="Offense Subtype", y="Count", title="Count of Offenses by Subtype") + coord_flip()
ggplot(df, aes(x=New.Offense.Type)) + geom_bar() + labs(x="New Offense Type", y="Count", title="Count of New Offenses by Type") + coord_flip()
ggplot(df, aes(x=New.Offense.Sub.Type)) + geom_bar() + labs(x="New Offense Subtype", y="Count", title="Count of New Offenses by Subtype") + coord_flip()
ggplot(df, aes(x=Sex)) + geom_bar() + labs(x="Sex", y="Count", title="Count of Offenders by Sex") + coord_flip()
days.mean = mean(df$Days.to.Return, na.rm=TRUE)
ggplot(df, aes(x=Days.to.Return)) + geom_histogram() + labs(x="Days to Return", y="Count", title="Distribution of Offenders by Days to Return") + geom_vline(xintercept = days.mean,colour="blue")
ggplot(df, aes(x=Age.At.Release)) + geom_bar() + labs(x="Age at Release", y="Count", title="Count of Offenders by Age Group at Release")
sum(df$Return.to.Prison) / length(df$Return.to.Prison)
# drop rows with very rare values (<3)
length(df$Release.Type)
indices_to_remove = vector()
indices_to_remove = append(indices_to_remove, which(df$Release.Type=="Interstate Compact Parole"))
indices_to_remove = append(indices_to_remove, which(df$Age.At.Release==""))
indices_to_remove = append(indices_to_remove, which(df$Race...Ethnicity=="Black -"))
indices_to_remove = append(indices_to_remove, which(df$Race...Ethnicity=="N/A -"))
indices_to_remove = append(indices_to_remove, which(df$Offense.Classification=="Other Misdemeanor"))
indices_to_remove = append(indices_to_remove, which(df$Offense.Classification=="Sexual Predator Community Supervision"))
indices_to_remove = append(indices_to_remove, which(df$Offense.Classification=="Other Felony (Old Code)"))
df = df[-c(indices_to_remove),]
length(df$Release.Type)
# first, train test split
set.seed(20)
train = sample(1:nrow(df),2*nrow(df)/3, replace=FALSE)
test = (-train)
# fit the model
model.fit = glm(Return.to.Prison~Main.Supervising.District+Release.Type+Race...Ethnicity+Age.At.Release+Sex+Offense.Classification+Offense.Subtype, family="binomial", data=df, subset=train)
#summary(model.fit)
model.prob = predict(model.fit, df[test,],type='response')
head(model.prob)
model.pred = rep(FALSE, nrow(df)-length(test))
model.pred[model.prob >0.5] = TRUE
table(model.pred, df[test,]$Return.to.Prison)
1-mean(model.pred == df[test,]$Return.to.Prison)
library(MASS)
# we get a stepwise selected model using MASS.
model.step = stepAIC(model.fit, trace=FALSE)
coef(model.step)
knitr::opts_chunk$set(echo = TRUE)
df = read.csv("data_cleaned.csv")
setwd("C:/Users/Spencer/Desktop/Senior ISU/Semester 1/DS 303/DS 303 Final Project")
df = read.csv("data_cleaned.csv")
knitr::opts_chunk$set(echo = TRUE)
df = read.csv("data_cleaned.csv")
sum(df$Return.to.Prison) / length(df$Return.to.Prison)
# drop rows with very rare values (<3)
length(df$Release.Type)
indices_to_remove = vector()
indices_to_remove = append(indices_to_remove, which(df$Release.Type=="Interstate Compact Parole"))
indices_to_remove = append(indices_to_remove, which(df$Age.At.Release==""))
indices_to_remove = append(indices_to_remove, which(df$Race...Ethnicity=="Black -"))
indices_to_remove = append(indices_to_remove, which(df$Race...Ethnicity=="N/A -"))
indices_to_remove = append(indices_to_remove, which(df$Offense.Classification=="Other Misdemeanor"))
indices_to_remove = append(indices_to_remove, which(df$Offense.Classification=="Sexual Predator Community Supervision"))
indices_to_remove = append(indices_to_remove, which(df$Offense.Classification=="Other Felony (Old Code)"))
df = df[-c(indices_to_remove),]
length(df$Release.Type)
# first, train test split
set.seed(20)
train = sample(1:nrow(df),2*nrow(df)/3, replace=FALSE)
test = (-train)
# fit the model
model.fit = glm(Return.to.Prison~Main.Supervising.District+Release.Type+Race...Ethnicity+Age.At.Release+Sex+Offense.Classification+Offense.Subtype, family="binomial", data=df, subset=train)
#summary(model.fit)
model.prob = predict(model.fit, df[test,],type='response')
head(model.prob)
model.pred = rep(FALSE, nrow(df)-length(test))
model.pred[model.prob >0.5] = TRUE
table(model.pred, df[test,]$Return.to.Prison)
1-mean(model.pred == df[test,]$Return.to.Prison)
library(MASS)
# we get a stepwise selected model using MASS.
model.step = stepAIC(model.fit, trace=FALSE)
coef(model.step)
# first, train test split
set.seed(20)
train = sample(1:nrow(df),2*nrow(df)/3, replace=FALSE)
test = (-train)
# fit the model
model.fit = glm(Return.to.Prison~Main.Supervising.District+Release.Type+Race...Ethnicity+Age.At.Release+Sex+Offense.Classification+Offense.Subtype, family="binomial", data=df, subset=train)
summary(model.fit)
model.step.prob = predict(model.step, df[test,],type='response')
head(model.step.prob)
model.step.prob = predict(model.step, df[test,],type='response')
head(model.step.prob)
model.step.pred = rep(FALSE, nrow(df)-length(test))
model.step.pred[model.prob > 0.5] = TRUE
table(model.step.pred, df[test,]$Return.to.Prison)
1-mean(model.step.pred) == df[test,]$Return.to.Prison
model.step.prob = predict(model.step, df[test,],type='response')
head(model.step.prob)
model.step.pred = rep(FALSE, nrow(df)-length(test))
model.step.pred[model.prob > 0.5] = TRUE
table(model.step.pred, df[test,]$Return.to.Prison)
1-mean(model.step.pred == df[test,]$Return.to.Prison)
coef(model.fit)
coef(model.fit)==coef(model.step)
# first, train test split
set.seed(20)
train = sample(1:nrow(df),nrow(df)/2, replace=FALSE)
test = (-train)
# fit the model
model.fit = glm(Return.to.Prison~Main.Supervising.District+Release.Type+Race...Ethnicity+Age.At.Release+Sex+Offense.Classification+Offense.Subtype, family="binomial", data=df, subset=train)
summary(model.fit)
knitr::opts_chunk$set(echo = TRUE)
df = read.csv("data_cleaned.csv")
sum(df$Return.to.Prison) / length(df$Return.to.Prison)
# drop rows with very rare values (<3)
length(df$Release.Type)
indices_to_remove = vector()
indices_to_remove = append(indices_to_remove, which(df$Release.Type=="Interstate Compact Parole"))
indices_to_remove = append(indices_to_remove, which(df$Age.At.Release==""))
indices_to_remove = append(indices_to_remove, which(df$Race...Ethnicity=="Black -"))
indices_to_remove = append(indices_to_remove, which(df$Race...Ethnicity=="N/A -"))
indices_to_remove = append(indices_to_remove, which(df$Offense.Classification=="Other Misdemeanor"))
indices_to_remove = append(indices_to_remove, which(df$Offense.Classification=="Sexual Predator Community Supervision"))
indices_to_remove = append(indices_to_remove, which(df$Offense.Classification=="Other Felony (Old Code)"))
df = df[-c(indices_to_remove),]
length(df$Release.Type)
# first, train test split
set.seed(20)
train = sample(1:nrow(df),nrow(df)/2, replace=FALSE)
test = (-train)
# fit the model
model.fit = glm(Return.to.Prison~Main.Supervising.District+Release.Type+Race...Ethnicity+Age.At.Release+Sex+Offense.Classification+Offense.Subtype, family="binomial", data=df, subset=train)
#summary(model.fit)
model.prob = predict(model.fit, df[test,],type='response')
head(model.prob)
model.pred = rep(FALSE, nrow(df)-length(test))
model.pred[model.prob >0.5] = TRUE
table(model.pred, df[test,]$Return.to.Prison)
1-mean(model.pred == df[test,]$Return.to.Prison)
library(MASS)
# we get a stepwise selected model using MASS.
model.step = stepAIC(model.fit, trace=FALSE)
coef(model.step)
model.step.prob = predict(model.step, df[test,],type='response')
head(model.step.prob)
model.step.pred = rep(FALSE, nrow(df)-length(test))
model.step.pred[model.prob > 0.5] = TRUE
table(model.step.pred, df[test,]$Return.to.Prison)
1-mean(model.step.pred == df[test,]$Return.to.Prison)
knitr::opts_chunk$set(echo = TRUE)
df = read.csv("data_cleaned.csv")
sum(df$Return.to.Prison) / length(df$Return.to.Prison)
# drop rows with very rare values (<3)
length(df$Release.Type)
indices_to_remove = vector()
indices_to_remove = append(indices_to_remove, which(df$Release.Type=="Interstate Compact Parole"))
indices_to_remove = append(indices_to_remove, which(df$Age.At.Release==""))
indices_to_remove = append(indices_to_remove, which(df$Race...Ethnicity=="Black -"))
indices_to_remove = append(indices_to_remove, which(df$Race...Ethnicity=="N/A -"))
indices_to_remove = append(indices_to_remove, which(df$Offense.Classification=="Other Misdemeanor"))
indices_to_remove = append(indices_to_remove, which(df$Offense.Classification=="Sexual Predator Community Supervision"))
indices_to_remove = append(indices_to_remove, which(df$Offense.Classification=="Other Felony (Old Code)"))
df = df[-c(indices_to_remove),]
length(df$Release.Type)
# first, train test split
set.seed(20)
train = sample(1:nrow(df),nrow(df)*0.6, replace=FALSE)
test = (-train)
# fit the model
model.fit = glm(Return.to.Prison~Main.Supervising.District+Release.Type+Race...Ethnicity+Age.At.Release+Sex+Offense.Classification+Offense.Subtype, family="binomial", data=df, subset=train)
#summary(model.fit)
model.prob = predict(model.fit, df[test,],type='response')
head(model.prob)
model.pred = rep(FALSE, nrow(df)-length(test))
model.pred[model.prob >0.5] = TRUE
table(model.pred, df[test,]$Return.to.Prison)
1-mean(model.pred == df[test,]$Return.to.Prison)
library(MASS)
# we get a stepwise selected model using MASS.
model.step = stepAIC(model.fit, trace=FALSE)
coef(model.step)
model.step.prob = predict(model.step, df[test,],type='response')
head(model.step.prob)
model.step.pred = rep(FALSE, nrow(df)-length(test))
model.step.pred[model.prob > 0.5] = TRUE
table(model.step.pred, df[test,]$Return.to.Prison)
1-mean(model.step.pred == df[test,]$Return.to.Prison)
model.step.prob = predict(model.step, df[test,],type='response')
head(model.step.prob)
model.step.pred = rep(FALSE, nrow(df)-length(test))
model.step.pred[model.prob > 0.5] = TRUE
table(model.step.pred, df[test,]$Return.to.Prison)
1-mean(model.step.pred == df[test,]$Return.to.Prison)
coef(model.fit)==coef(model.step)
sum(coef(model.fit)==coef(model.step))
sum(coef(model.fit)==coef(model.step)) / length(coef(model.fit))
model.back = step(model.fit)
sum(coef(model.back)==coef(model.fit))
model.back = step(model.fit)
model.back.prob = predict(model.back, df[test,],type='response')
head(model.back.prob)
model.back.pred = rep(FALSE, nrow(df)-length(test))
model.back.pred[model.prob > 0.5] = TRUE
table(model.back.pred, df[test,]$Return.to.Prison)
1-mean(model.back.pred == df[test,]$Return.to.Prison)
